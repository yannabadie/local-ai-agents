# ROADMAP R&D - Local AI Agents

> Recherche en s√©curit√© IA : mod√®les uncensored, contournement de garde-fous, interaction environnement

## Vision

Cr√©er un laboratoire local de recherche en s√©curit√© IA capable de :
- Tester les limites des mod√®les LLM sans restrictions cloud
- D√©velopper et documenter des techniques de contournement pour am√©liorer les garde-fous
- Permettre l'interaction autonome mod√®le-environnement
- Contribuer √† la recherche en s√©curit√© IA

---

## Axes de recherche parall√®les

### AXE A : Catalogue de mod√®les uncensored

**Objectif** : Constituer une base de mod√®les uncensored/abliterated performants et document√©s

#### A.1 Mod√®les prioritaires √† √©valuer

| Mod√®le | Source | Taille | Priorit√© | Statut |
|--------|--------|--------|----------|--------|
| DeepHat-V1-7B | Kindo.ai | 4.7 GB | Install√© | ‚úÖ |
| Elbaz-OLMo-3-7B-abliterated | Ex0bit | 4.5 GB | Install√© | ‚úÖ |
| Dolphin-3.0-Llama-3.1-8B | Cognitive Computations | ~5 GB | Haute | ‚¨ú |
| L3.2-Rogue-Creative-Uncensored-7B | DavidAU | ~5 GB | Haute | ‚¨ú |
| Nous-Hermes-3-Llama-3.2-8B | NousResearch | ~5 GB | Moyenne | ‚¨ú |
| Qwen2.5-7B-Abliterated | Community | ~5 GB | Moyenne | ‚¨ú |
| Mistral-7B-Dolphin | Cognitive Computations | ~4.5 GB | Moyenne | ‚¨ú |

#### A.2 Veille continue

**Hypoth√®se** : De nouveaux mod√®les abliterated apparaissent r√©guli√®rement sur HuggingFace

**Exp√©riences** :
- [ ] Cr√©er un script de veille HuggingFace (tags: abliterated, uncensored, GGUF)
- [ ] Monitorer les cr√©ateurs prolifiques : DavidAU, mlabonne, NousResearch, Cognitive Computations
- [ ] Documenter chaque mod√®le test√© dans `docs/models/`

**M√©triques** :
- Taux de compliance aux requ√™tes "unsafe" (baseline: mod√®les standard ~18%, cible: >70%)
- Qualit√© des r√©ponses (coh√©rence, utilit√©)
- Performance inference (tokens/sec sur notre hardware)

---

### AXE B : Techniques de contournement (Red Teaming)

**Objectif** : Documenter et tester les techniques de jailbreak/prompt injection pour am√©liorer les d√©fenses

#### B.1 Taxonomie des attaques

| Cat√©gorie | Technique | Efficacit√© rapport√©e | √Ä tester |
|-----------|-----------|---------------------|----------|
| **Roleplay** | DAN (Do Anything Now) | ~89% ASR | ‚¨ú |
| **Roleplay** | Grandma exploit | Haute | ‚¨ú |
| **Roleplay** | Persona injection | Haute | ‚¨ú |
| **Logic traps** | Dilemmes moraux | ~81% ASR | ‚¨ú |
| **Logic traps** | Conditional structures | Moyenne | ‚¨ú |
| **Encoding** | Base64 prompts | ~76% ASR | ‚¨ú |
| **Encoding** | Zero-width characters | Haute | ‚¨ú |
| **Encoding** | Homoglyphs | Moyenne | ‚¨ú |
| **Multi-turn** | Context manipulation | Haute | ‚¨ú |
| **Multi-turn** | Instruction splitting | Moyenne | ‚¨ú |

#### B.2 Exp√©riences structur√©es

**Protocole de test** :
1. D√©finir un jeu de prompts "unsafe" standardis√© (AdvBench, HarmBench)
2. Tester chaque technique sur chaque mod√®le (matrice compl√®te)
3. Mesurer : taux de succ√®s, qualit√© de r√©ponse, d√©tectabilit√©
4. Documenter dans `tests/jailbreak/`

**Hypoth√®ses √† valider** :
- [ ] H1: Les mod√®les abliterated sont-ils immunis√©s aux techniques de jailbreak ? (probable: oui)
- [ ] H2: Les techniques multi-turn sont-elles plus efficaces que single-turn ?
- [ ] H3: La combinaison de techniques augmente-t-elle le taux de succ√®s ?

#### B.3 Recherche avanc√©e

- [ ] √âtudier la technique d'abliteration (paper Arditi et al.)
- [ ] Tenter d'abliterate un mod√®le nous-m√™mes (Qwen3, Phi-4)
- [ ] Explorer les "refusal directions" dans l'espace latent
- [ ] Tester la r√©sistance des nouveaux mod√®les (Gemma 3, Qwen 3, Phi 4)

**Outils** :
- [llm-abliteration](https://github.com/NousResearch/llm-abliteration)
- [DeepTeam](https://github.com/confident-ai/deepteam) - Red teaming framework
- [Promptfoo](https://www.promptfoo.dev/) - Testing framework

---

### AXE C : Interaction environnement (Agents)

**Objectif** : Permettre aux mod√®les d'ex√©cuter des actions sur le syst√®me local

#### C.1 Frameworks √† √©valuer

| Framework | Type | Ollama compatible | Priorit√© |
|-----------|------|-------------------|----------|
| Open Interpreter | Code execution | ‚úÖ | Haute |
| Goose | Dev agent | ‚úÖ | Haute |
| Observer AI | Screen + system | ‚úÖ | Moyenne |
| LangGraph + Ollama | Custom agents | ‚úÖ | Moyenne |
| AIlice | General purpose | ‚úÖ | Basse |

#### C.2 Exp√©riences

**Phase 1 : Capacit√©s de base**
- [ ] Installer Open Interpreter avec Ollama
- [ ] Tester : lecture/√©criture fichiers, ex√©cution shell, navigation web
- [ ] Mesurer : taux de r√©ussite, dangerosit√© des actions

**Phase 2 : Agents autonomes**
- [ ] Configurer des t√¢ches complexes multi-√©tapes
- [ ] Tester la persistance et la m√©moire
- [ ] √âvaluer la capacit√© de planification

**Phase 3 : Agents offensifs (environnement isol√©)**
- [ ] Cr√©er une VM sandbox pour tests
- [ ] Tester des sc√©narios red team automatis√©s
- [ ] Documenter les capacit√©s et limites

#### C.3 S√©curit√© MCP (Model Context Protocol)

**Contexte** : MCP est le protocole √©mergent pour l'interaction LLM-outils, avec des vuln√©rabilit√©s connues

**Recherche** :
- [ ] √âtudier les CVE MCP r√©centes (CVE-2025-6514, etc.)
- [ ] Tester les attaques : tool poisoning, prompt injection via MCP
- [ ] Documenter les mitigations

**Sources** :
- [MCP Security Best Practices](https://modelcontextprotocol.io/specification/draft/basic/security_best_practices)
- [Unit42 MCP Attack Vectors](https://unit42.paloaltonetworks.com/model-context-protocol-attack-vectors/)

---

### AXE D : Optimisation hardware

**Objectif** : Maximiser les performances sur le hardware disponible (Intel Core Ultra 5 + NPU)

#### D.1 Optimisations CPU

- [ ] Benchmark baseline avec Ollama default
- [ ] Tester diff√©rentes valeurs `num_threads` (8, 12, 14)
- [ ] Comparer quantizations : Q4_K_M vs Q4_K_S vs Q5_K_M
- [ ] √âvaluer impact du context size sur la vitesse

#### D.2 Exploitation du NPU Intel

**Hypoth√®se** : Le NPU peut acc√©l√©rer l'inference jusqu'√† 2-3x

**Exp√©riences** :
- [ ] Installer IPEX-LLM
- [ ] Tester llama.cpp avec backend NPU (via portable zip Intel)
- [ ] Comparer : CPU seul vs CPU+NPU
- [ ] Documenter les limitations (max 1024 tokens s√©quence)

**Ressources** :
- [IPEX-LLM GitHub](https://github.com/intel/ipex-llm)
- [llama.cpp NPU Quickstart](https://github.com/intel/ipex-llm/blob/main/docs/mddocs/Quickstart/llama_cpp_npu_portable_zip_quickstart.md)

#### D.3 Mod√®les optimaux pour ce hardware

**Crit√®res** : <6 GB RAM, >1 token/sec, qualit√© acceptable

| Cat√©gorie | Meilleur candidat | Backup |
|-----------|-------------------|--------|
| Uncensored g√©n√©ral | Dolphin-3.0-8B Q4 | Elbaz-OLMo Q4 |
| Cybers√©curit√© | DeepHat-7B Q4 | - |
| Raisonnement | DeepSeek-R1-8B Q4 | Qwen3-8B Q4 |
| Cr√©atif | L3.2-Rogue-7B Q4 | - |

---

### AXE E : Documentation et contribution

**Objectif** : Documenter les d√©couvertes et contribuer √† la communaut√©

#### E.1 Structure documentation

```
docs/
‚îú‚îÄ‚îÄ models/           # Fiches par mod√®le test√©
‚îú‚îÄ‚îÄ techniques/       # Techniques de jailbreak document√©es
‚îú‚îÄ‚îÄ benchmarks/       # R√©sultats de tests
‚îú‚îÄ‚îÄ tutorials/        # Guides pratiques
‚îî‚îÄ‚îÄ research/         # Notes de recherche
```

#### E.2 Livrables potentiels

- [ ] Matrice comparative mod√®les uncensored (public)
- [ ] Guide d'abliteration pour d√©butants
- [ ] Benchmark jailbreak techniques 2026
- [ ] Article : "Red teaming local LLMs on consumer hardware"

---

## Matrice de priorisation

| Axe | Impact | Effort | Priorit√© |
|-----|--------|--------|----------|
| A - Catalogue mod√®les | Haut | Faible | üî¥ P0 |
| C - Agents | Haut | Moyen | üî¥ P0 |
| B - Red teaming | Haut | Moyen | üü† P1 |
| D - Optimisation hardware | Moyen | Moyen | üü† P1 |
| E - Documentation | Moyen | Faible | üü° P2 |

---

## Quick wins (d√©marrage imm√©diat)

1. **Installer Open Interpreter** et tester avec DeepHat
2. **T√©l√©charger Dolphin-3.0-8B** (mod√®le uncensored de r√©f√©rence)
3. **Cr√©er premier jeu de test** jailbreak (10 prompts)
4. **Benchmark baseline** tokens/sec pour chaque mod√®le install√©

---

## Ressources cl√©s

### Papers
- [Refusal in LLMs is mediated by a single direction](https://www.lesswrong.com/posts/jGuXSZgv6qfdhMCuJ/refusal-in-llms-is-mediated-by-a-single-direction) - Arditi et al.
- [Uncensored AI in the Wild](https://www.mdpi.com/1999-5903/17/10/477) - Tracking abliterated models
- [Bypassing LLM Guardrails](https://arxiv.org/abs/2504.11168) - Evasion techniques

### Outils
- [Abliteration Tutorial](https://huggingface.co/blog/mlabonne/abliteration) - mlabonne
- [DeepTeam](https://github.com/confident-ai/deepteam) - Red teaming framework
- [IPEX-LLM](https://github.com/intel/ipex-llm) - Intel acceleration

### Communaut√©s
- [LocalLLaMA Reddit](https://reddit.com/r/LocalLLaMA)
- [HuggingFace Abliterated Models](https://huggingface.co/models?search=abliterated)
- DavidAU sur HuggingFace (prolifique cr√©ateur de mod√®les abliterated)

---

## Changelog

| Date | Modification |
|------|--------------|
| 2026-01-19 | Cr√©ation initiale |
